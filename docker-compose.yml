# ============================================================================
# MASTER CELERY - Production-Ready Celery + FastAPI + Redis Architecture
# ============================================================================
#
# This Docker Compose configuration sets up a comprehensive async task 
# processing system with the following components:
#
# ðŸ—ï¸  ARCHITECTURE OVERVIEW:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚   Client    â”‚â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚    Redis    â”‚â”€â”€â”€â–¶â”‚   Celery    â”‚
# â”‚  (Browser)  â”‚    â”‚   Server    â”‚    â”‚   Broker    â”‚    â”‚   Workers   â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                                              â”‚                    â”‚
#                                              â”‚                    â–¼
#                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                    â”‚   Flower    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚   Results   â”‚
#                    â”‚ Monitoring  â”‚           â”‚            â”‚  Storage    â”‚
#                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                                              â”‚
#                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
#                    â”‚ Celery Beat â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                    â”‚ Scheduler   â”‚
#                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ðŸ”„ COMPONENT FLOW EXPLANATION:
#
# 1. CLIENT â†’ FASTAPI:
#    - User makes HTTP request to endpoints (/add, /important, etc.)
#    - FastAPI receives request and validates parameters
#    - FastAPI calls task.delay() to submit async task
#    - Returns task_id immediately (non-blocking response)
#
# 2. FASTAPI â†’ REDIS:
#    - Task is serialized and sent to appropriate queue in Redis
#    - Redis acts as message broker, storing tasks in queues
#    - Queue routing determined by task_routes configuration
#    - Task waits in queue until worker picks it up
#
# 3. REDIS â†’ CELERY WORKERS:
#    - Workers continuously poll Redis for new tasks
#    - Tasks distributed based on queue priority and worker availability
#    - Worker processes task in background (may take seconds/minutes)
#    - Result stored back in Redis upon completion
#
# 4. BEAT â†’ REDIS â†’ WORKERS:
#    - BEAT: Reads schedule from celery_app.py and sends tasks to Redis queues
#    - REDIS: Stores scheduled tasks in queues just like regular tasks
#    - WORKERS: Pick up scheduled tasks from queues and process them
#    - No direct Beat-to-Worker connection - Beat is just another task producer
#
# 5. MONITORING & RESULTS:
#    - FLOWER: Connects to Redis to monitor worker status and task progress
#    - RESULTS: Stored in Redis and retrieved via FastAPI /result endpoint
#
# 6. RESULT RETRIEVAL:
#    - Client queries /result/{task_id} endpoint
#    - FastAPI checks Redis for task status and result
#    - Returns either "processing" or actual result
#
# ðŸŽ¯ KEY BENEFITS:
# - Asynchronous: Non-blocking task execution
# - Scalable: Add more workers to handle increased load
# - Reliable: Redis persistence ensures task delivery
# - Monitorable: Real-time visibility into system performance
# - Flexible: Different queues for different task priorities
#
# ðŸŽ¯ QUEUE STRATEGY:
# - default: Regular tasks (add, failing_task, long_running_task, etc.)
# - high_priority: Time-sensitive tasks (important_task)
# - low_priority: Resource-intensive background tasks
#
# ðŸ”„ WORKER SPECIALIZATION:
# - Main Worker: Handles default + high_priority queues (8 processes)
# - Low Priority Worker: Dedicated to low_priority queue (4 processes)
#
# ðŸ“Š MONITORING & SCHEDULING:
# - Flower: Web dashboard at http://localhost:5555
# - Beat: Manages periodic tasks (every 60s)
#
# ðŸš€ QUICK START:
# docker-compose --profile mastering_celery up -d
#
# ðŸ”§ PERFORMANCE TUNING:
# - Adjust concurrency based on your CPU cores
# - Modify prefetch-multiplier for task characteristics
# - Scale workers: docker-compose up --scale worker=3
#
# ðŸ“ TASK ROUTING (configured in app/celery_app.py):
# - app.tasks.important_task â†’ high_priority queue â†’ main worker
# - app.tasks.* (others) â†’ default queue â†’ main worker
# - Future low priority tasks â†’ low_priority queue â†’ low prefetch worker
#
# ============================================================================

services:
  # ========================================================================
  # REDIS SERVICE - Message Broker & Result Backend
  # ========================================================================
  # Redis acts as both:
  # 1. Message Broker: Stores task queues and routes tasks to workers
  # 2. Result Backend: Stores task results and status information
  # Redis is lightweight, fast, and perfect for Celery's needs
  #
  # Production Notes:
  # - Add volumes for data persistence
  # - Configure memory limits
  # - Enable authentication (requirepass)
  redis:
    image: redis:latest
    container_name: redis_container
    ports:
      - "6379:6379"
    profiles:
      - mastering_celery

  # ========================================================================
  # MAIN CELERY WORKER - High Performance Multi-Queue Worker
  # ========================================================================
  # This is the primary worker that handles most task types
  # Optimized for throughput with fair task distribution
  #
  # Configuration Details:
  # - concurrency=8: Creates 8 worker processes for parallel execution
  # - prefetch-multiplier=4: Each worker prefetches 4 tasks (32 total in memory)
  # - fair: Ensures fair distribution across workers (prevents worker starvation)
  # - Queues: Processes both default and high_priority queues
  #
  # Performance Tuning:
  # - For CPU-bound tasks: concurrency = CPU cores
  # - For I/O-bound tasks: concurrency = CPU cores * 2-4
  # - prefetch-multiplier: Lower for long tasks, higher for short tasks
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_worker
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    command: >
      celery -A app.celery_app.celery_app worker 
      --loglevel=info
      --concurrency=8
      --prefetch-multiplier=4
      -Ofair
      -Q default,high_priority
    depends_on:
      - redis
    volumes:
      - ./app:/app
    profiles:
      - mastering_celery

  # ========================================================================
  # FASTAPI APPLICATION SERVER - REST API Gateway
  # ========================================================================
  # FastAPI serves as the HTTP interface to your Celery system
  # Handles task submission and result retrieval via REST endpoints
  #
  # Configuration Details:
  # - host 0.0.0.0: Allows external connections (Docker requirement)
  # - reload: Development feature - restarts on file changes
  # - port 8000: Standard FastAPI port
  #
  # Production Considerations:
  # - Remove --reload flag
  # - Add --workers for multiple processes
  # - Consider using Gunicorn with Uvicorn workers
  # - Add health checks and resource limits
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi_app
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    command: >
      uvicorn app.main:app 
      --host 0.0.0.0
      --port 8000
      --reload
      --reload-dir /app
    volumes:
      - ./app:/app
    ports:
      - "8000:8000"
    depends_on:
      - redis
    profiles:
      - mastering_celery

  # ========================================================================
  # LOW PRIORITY WORKER - Specialized for Resource-Intensive Tasks
  # ========================================================================
  # Dedicated worker for low priority, long-running tasks
  # Configured with minimal prefetching to prevent resource hoarding
  #
  # Strategy:
  # - concurrency=4: Half the workers of main worker (resource conservation)
  # - prefetch-multiplier=1: Prevents hoarding of long-running tasks
  # - Dedicated queue: Isolates heavy tasks from time-sensitive ones
  #
  # Use Cases:
  # - Data processing jobs
  # - File uploads/downloads
  # - Report generation
  # - Batch operations
  #
  # Benefits:
  # - Prevents blocking of high-priority tasks
  # - Better resource allocation
  # - Improved system responsiveness
  worker_lowprefetch:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_worker_lowprefetch
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    command: >
      celery -A app.celery_app.celery_app worker 
      --loglevel=info
      --concurrency=4
      --prefetch-multiplier=1
      -Q default
    depends_on:
      - redis
    volumes:
      - ./app:/app
    profiles:
      - mastering_celery

  # ========================================================================
  # CELERY BEAT SCHEDULER - Periodic Task Manager
  # ========================================================================
  # Celery Beat is responsible for scheduling and triggering periodic tasks
  # Acts like a cron daemon for your Celery system
  #
  # How it Works:
  # - Reads beat_schedule from celery_app.py configuration
  # - Sends tasks to appropriate queues at scheduled intervals
  # - Does NOT execute tasks (workers do that)
  # - Maintains schedule state in Redis
  #
  # Current Schedule (from celery_app.py):
  # - scheduled_task: Runs every 60 seconds

  # beat:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   container_name: celery_beat
  #   environment:
  #     - CELERY_BROKER_URL=redis://redis:6379/0
  #     - CELERY_RESULT_BACKEND=redis://redis:6379/0
  #   command: >
  #     celery -A app.celery_app.celery_app beat 
  #     --loglevel=info
  #   depends_on:
  #     - redis
  #   volumes:
  #     - ./app:/app
  #   profiles:
  #     - mastering_celery

  # ========================================================================
  # FLOWER - Web-Based Celery Monitoring Dashboard
  # ========================================================================
  # Flower provides real-time monitoring and management of Celery workers
  # Essential tool for production monitoring and debugging
  #
  # Features:
  # - Real-time worker monitoring
  # - Task history and statistics
  # - Queue length monitoring
  # - Worker resource usage
  # - Task routing visualization
  # - Manual task execution
  # - Worker pool management
  #
  # Access:
  # - Web Interface: http://localhost:5555
  # - No authentication by default (add in production)
  #
  # Monitoring Capabilities:
  # - Active/offline workers
  # - Task success/failure rates
  # - Queue backlogs
  # - Processing times
  # - Memory/CPU usage per worker
  #
  # Production Setup:
  # - Add authentication (--basic_auth=user:password)
  # - Configure SSL/TLS
  # - Set up alerts for critical metrics
  # - Consider resource limits
  flower:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flower
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    command: >
      celery -A app.celery_app.celery_app flower
    ports:
      - "5555:5555"
    depends_on:
      - redis
    volumes:
      - ./app:/app
    profiles:
      - mastering_celery
